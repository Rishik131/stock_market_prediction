{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "company = 'FB'\n",
    "start = dt.datetime(2012,1,1)\n",
    "end = dt.datetime(2020,1,1)\n",
    "data = pdr.DataReader(company,'yahoo',start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_days = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(prediction_days,len(scaled_data)):\n",
    "    x_train.append(scaled_data[x-prediction_days:x,0])\n",
    "    y_train.append(scaled_data[x,0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "#predicting next closing value\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "59/59 [==============================] - 24s 148ms/step - loss: 0.0281\n",
      "Epoch 2/25\n",
      "59/59 [==============================] - 9s 146ms/step - loss: 0.0054\n",
      "Epoch 3/25\n",
      "59/59 [==============================] - 10s 166ms/step - loss: 0.0036\n",
      "Epoch 4/25\n",
      "59/59 [==============================] - 10s 166ms/step - loss: 0.0033\n",
      "Epoch 5/25\n",
      "59/59 [==============================] - 10s 171ms/step - loss: 0.0036\n",
      "Epoch 6/25\n",
      "59/59 [==============================] - 10s 170ms/step - loss: 0.0035\n",
      "Epoch 7/25\n",
      "59/59 [==============================] - 10s 170ms/step - loss: 0.0030\n",
      "Epoch 8/25\n",
      "59/59 [==============================] - 10s 169ms/step - loss: 0.0032\n",
      "Epoch 9/25\n",
      "59/59 [==============================] - 10s 171ms/step - loss: 0.0029\n",
      "Epoch 10/25\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 0.0025\n",
      "Epoch 11/25\n",
      "59/59 [==============================] - 10s 166ms/step - loss: 0.0034\n",
      "Epoch 12/25\n",
      "59/59 [==============================] - 9s 145ms/step - loss: 0.0027\n",
      "Epoch 13/25\n",
      "59/59 [==============================] - 8s 138ms/step - loss: 0.0024\n",
      "Epoch 14/25\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 0.0026\n",
      "Epoch 15/25\n",
      "59/59 [==============================] - 8s 138ms/step - loss: 0.0023\n",
      "Epoch 16/25\n",
      "59/59 [==============================] - 8s 135ms/step - loss: 0.0023\n",
      "Epoch 17/25\n",
      "59/59 [==============================] - 8s 139ms/step - loss: 0.0022\n",
      "Epoch 18/25\n",
      "59/59 [==============================] - 8s 139ms/step - loss: 0.0033\n",
      "Epoch 19/25\n",
      "59/59 [==============================] - 8s 141ms/step - loss: 0.0024\n",
      "Epoch 20/25\n",
      "59/59 [==============================] - 8s 142ms/step - loss: 0.0027\n",
      "Epoch 21/25\n",
      "59/59 [==============================] - 8s 143ms/step - loss: 0.0021\n",
      "Epoch 22/25\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 0.0022\n",
      "Epoch 23/25\n",
      "59/59 [==============================] - 8s 136ms/step - loss: 0.0021\n",
      "Epoch 24/25\n",
      "59/59 [==============================] - 8s 143ms/step - loss: 0.0019\n",
      "Epoch 25/25\n",
      "59/59 [==============================] - 8s 143ms/step - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209827b9fa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(x_train,y_train,epochs=25,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://769e421b-ee52-428f-862d-2ed8c56b51ba/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://769e421b-ee52-428f-862d-2ed8c56b51ba/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002098228E940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000020982446A00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000020982553F40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test_start = dt.datetime(2020,1,1)\n",
    "test_end = dt.datetime.now()\n",
    "\n",
    "test_data = pdr.DataReader(company,'yahoo',test_start,test_end)\n",
    "actual_prices = test_data['Close'].values\n",
    "\n",
    "total_dataset = pd.concat((data['Close'], test_data['Close']),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = total_dataset[len(total_dataset) - len(test_data) - prediction_days:].values.reshape(-1,1)\n",
    "model_inputs = scaler.transform(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making prediction\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b13743b7925013cae76829faecf5e9d4050d80f816c7d68a6257c9b33a3ff4dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
